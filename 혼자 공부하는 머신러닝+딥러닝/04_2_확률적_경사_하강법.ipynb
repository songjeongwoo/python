{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-2 확률적 경사 하강법.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 확률적 경사 하강법(SGD, Stochastic Gradient Descent)\n",
        "- \"랜덤하게 경사(기울기)를 내려가는 방법\"<br>\n",
        "- 점진적 학습의 최적화 방법 중 하나<br>\n",
        "cf) 점진적 학습: 모델 서비스 도중 업데이트(온라인 학습) / 모델 서비스 중지하고 업데이트 후 재개\n",
        "- ML/DL 알고리즘을 훈련하는(최적화하는) 방법<br>\n",
        "- 훈련 세트에서 샘플 한 개를 랜덤하게 선택하여 경사를 내려감(모든 샘플을 다 사용할 때까지).\n",
        "- 훈련 세트를 한 번 모두 사용하는 과정을 **에포크(epoch)**라고 함.\n",
        "<br><br>\n",
        "- **미니배치 경사 하강법(minibatch gradient descent)**: 무작위로 몇 개의 샘플을 선택해서 경사를 내려감.\n",
        "  - <u>실전에서 많이 사용됨</u>.\n",
        "<br><br>\n",
        "- **배치 경사 하강법(batch gradient descent)**: 전체 샘플을 사용해서 경사를 내려감.\n",
        "  - 전체 데이터를 사용하기 때문에 가장 안정적인 방법일 수 있으나, 컴퓨터 자원을 많이 사용하게 됨.\n",
        "  - 데이터가 너무 많으면 한 번에 전체 데이터를 모두 읽을 수 없을 수 도 있음.\n",
        "<br><br>\n",
        "- 신경망 알고리즘(Neural Network, DL)에서는 확률적 경사 하강법을 꼭 사용.\n",
        "  - 신경망은 일반적으로 많은 데이터를 사용하기 때문에, **확률적 경사 하강법** 또는 **미니배치 경사 하강법**을 사용함.\n",
        "<br><br>\n",
        "\n",
        "- cf) 경사를 너무 빨리 내려올 경우, 아래의 그림 중 3번째 그림과 같이 될 수 있다.\n",
        "<img src='https://miro.medium.com/max/600/1*Q-2Wh0Xcy6fsGkbPFJvMhQ.gif'><br>\n",
        "<small><font color='gray'>출처: https://medium.com/x8-the-ai-community/gradient-descent-intuition-how-machines-learn-d29ad7464453</font></small><br>"
      ],
      "metadata": {
        "id": "8vfHYKBDm84_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 17'00쯤 ~"
      ],
      "metadata": {
        "id": "Y2e2ouh-GFCV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 손실함수\n",
        "- 어떤 문제에서 ML알고리즘이 얼마나 엉터리인지를 측정하는 함수\n",
        "- 비용함수(cost function)과 동의어로 볼 수 있다.\n",
        "  - 엄밀히 따지면, 손실함수는 샘플 하나에 대한 손실을 정의\n",
        "  - 비용함수는 훈련 세트에 있는 모든 샘플에 대한 손실 함수의 합을 뜻함.\n",
        "<br><br>\n",
        "- **확률 경사 하강법**은 **이 <u>손실함수 값이 작아지도록</u> 가중치(기울기), 편향(절편) 값들을 업데이트 하는 것**이다.\n",
        "- 손실함수는 미분가능해야한다.\n",
        "  - 분류문제의 정확도(accuracy)는 미분이 가능하지 않기때문에, 즉 연속적이지 않기 때문에 손실함수로 사용할 수 없는 측정방법 중 하나이다.\n",
        "  - ex) 4개의 샘플에 대해 정확도는 0, 0.25, 0.5, 0.75, 1 다섯가지 뿐이다. → **연속적이지 않기 때문에 경사하강법을 사용할 수 없음.**\n",
        "  - 따라서 분류문제에서는 **정확도(accuracy)로 성능을 측정**하지만, 모델을 최적화할 때는 다른 손실함수를 쓴다.\n",
        "- 분류일 때, 손실함수로 **로지스틱 손실 함수(logistic loss function)** 또는 **이진 크로스 엔트로피 손실 함수(binary cross-entropy loss function)**를 쓴다.\n",
        "<br><br>\n",
        "- cf) 회귀의 경우, 미분 가능한 **평균 절대값 오차(MAE) 또는 평균 제곱 오차(MSE)**를 손실함수로 사용할 수 있다.\n",
        "  - 따라서 **회귀에서는 손실함수와 측정지표를 동일하게** 가져갈 수 있다."
      ],
      "metadata": {
        "id": "TJLSxEm8Isuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 로지스틱 손실 함수(logistic loss function)\n",
        "- 또는 이진 크로스 엔트로피 손실 함수(binary cross-entropy loss function)\n"
      ],
      "metadata": {
        "id": "sTZNTyFjQ8fi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ex)<br>\n",
        "예측$\\quad$정답(타겟)$\\quad$예측확률<br>\n",
        "\n",
        "$\\;1\\quad=\\quad1$$\\quad\\quad\\quad\\quad$0.9<br>\n",
        "$\\;0\\quad\\neq\\quad1$$\\quad\\quad\\quad\\quad$0.3<br>\n",
        "$\\;0\\quad=\\quad0$$\\quad\\quad\\quad\\quad$0.2<br>\n",
        "$\\;1\\quad\\neq\\quad0$$\\quad\\quad\\quad\\quad$0.8<br><br>\n",
        "\n",
        "$\\quad\\quad\\quad\\quad\\quad\\Downarrow$<br><br>\n",
        "\n",
        "- 정답이 1일 경우, `(-1) * 1(양성클래스) * 예측확률`<br>\n",
        "- 정답이 0일 경우, 양성클래스처럼 바꿔서 처리한다.\n",
        " `(-1) * 1(양성클래스) * (1 - 예측확률)`<br>\n",
        "\n",
        "예측$\\quad$정답(타겟)$\\quad$예측확률$\\quad$손실<br>\n",
        "\n",
        "$\\;1\\quad\\neq\\quad1$$\\quad\\quad\\quad\\quad$0.9$\\quad$$\\quad$-0.9 (-1 * 1 * 0.9)<br>\n",
        "$\\;0\\quad\\neq\\quad1$$\\quad\\quad\\quad\\quad$0.3$\\quad$$\\quad$-0.3 (-1 * 1 * 0.3)<br>\n",
        "$\\;0\\quad=\\quad0$$\\quad\\quad\\quad\\quad$0.2$\\quad$$\\quad$-0.8 (-1 * 1 * (1 - 0.2))<br>\n",
        "$\\;1\\quad\\neq\\quad0$$\\quad\\quad\\quad\\quad$0.8$\\quad$$\\quad$-0.2 (-1 * 1 * (1 - 0.8))<br><br>\n",
        "\n",
        "예측 확률을 사용해 이런 식으로 계산하면 연속적인 손실 함수를 얻을 수 있다.<br>\n",
        "여기에서 예측 확률에 로그 함수를 적용하면 더 좋다.<br>\n",
        "예측 확률의 범위는 0~1 사이인데 로그함수는 이 사이에서 음수가 되므로 최종 손실 값은 양수가 되기 때문이다.<br>\n",
        "또한 로그함수는 0에 가까울수록 아주 큰 음수가 되기 때문에 손실을 아주 크게 만들어 모델에 큰 영향을 미칠 수 있다.<br><br>\n",
        "cf) 로그함수<br><br>\n",
        "<img src='https://ww.namu.la/s/d6acfbc3de1edf2cdb37867f48bfeb687549fba33195a7448d84defb13b41ba458e90f57e6808be2fa4faf7c2ee25568e8af44ff1e272af1e39daac6cac97e377b4c52f82210f30658dbb7fea51972cf' width=400><br>\n",
        "<small><font color='gray'>출처: https://namu.wiki/w/%EB%A1%9C%EA%B7%B8%ED%95%A8%EC%88%98</font></small><br>\n",
        "\n",
        "타겟 = 1일 때: $-log(예측 확률)$<br>\n",
        "타겟 = 0일 때: $-log(1-예측 확률)$<br>\n",
        "\n",
        "cf) $-log x = log_{\\frac{1}{10}} x$<br>\n",
        "<img src='https://mblogthumb-phinf.pstatic.net/MjAxOTEwMjBfMjcx/MDAxNTcxNTczOTkzNjg2.Mrzu4T_rYP8dRBz1udLWCpcbMq_WZRuEvQwaI8-iUVYg.yMDuR3PP8N0KghQ698wa5mzyZasX5aSn4zh2a394HZog.PNG.ppos78/%EC%A7%80%EC%88%98%ED%95%A8%EC%88%98%EC%99%80-%EB%A1%9C%EA%B7%B8%ED%95%A8%EC%88%98%EC%9D%98-%EA%B7%B9%ED%95%9C-01.png?type=w2'><br>\n",
        "- cf) a가 10일때와 $\\frac{1}{10}$일 때를 가정<br>\n",
        "<small><font color='gray'>출처: https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=ppos78&logNo=221683505743</font></small><br>\n",
        "\n"
      ],
      "metadata": {
        "id": "eKKWLrnbBB9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 31'38부터"
      ],
      "metadata": {
        "id": "nXVIGUo6RLtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리"
      ],
      "metadata": {
        "id": "VBDT-j7y-Akl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "tykSWW0DIUvO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fish = pd.read_csv('https://bit.ly/fish_csv_data')\n",
        "x = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n",
        "y = fish['Species'].to_numpy()"
      ],
      "metadata": {
        "id": "H7gpLiE6IXQE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "483xcQmDIquQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
      ],
      "metadata": {
        "id": "AkLrrULWIvPC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "lIHFIyboI45j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경사 하강법 사용을 위해선 특성마다 스케일이 같아야한다.\n",
        "# 스케일이 다르다면 경사를 공평하게 평가할 수 없다.\n",
        "# 따라서 경사 하강법 알고리즘을 사용할 때에는 반드시 데이터를 전처리해서 표준점수로 특성의 스케일을 바꿔줘야한다.\n",
        "ss = StandardScaler()\n",
        "ss.fit(x_train)\n",
        "train_scaled = ss.transform(x_train)\n",
        "test_scaled = ss.transform(x_test)"
      ],
      "metadata": {
        "id": "0EcU1IfiJCfW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGDClassifier\n",
        "- 사이킷런에서 제공하는 확률적 경사 하강법 알고리즘\n",
        "  - 배치 또는 미니배치 경사 하강법은 지원하지 않음\n",
        "- 회귀 문제일 경우, SGDRegressor\n",
        "- 머신러닝 모델이 아니라 머신러닝 모델을 최적화하는 방법 중 하나이다.\n",
        "  - loss 하이퍼파라미터에서 어떤 모델을 최적화할 지 정해준다."
      ],
      "metadata": {
        "id": "FeaDRRZbJU8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 불러오기\n",
        "from sklearn.linear_model import SGDClassifier"
      ],
      "metadata": {
        "id": "zrNFheBDLbrW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선언하기  # max_iter: 훈련 세트를 몇 번 사용할 지(=epochs)\n",
        "sc = SGDClassifier(loss='log', max_iter=10, random_state=42)"
      ],
      "metadata": {
        "id": "1O3Gm6R2Lnkd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- loss 속성값으로 log를 준 것은 로지스틱 손실함수(이진 크로스엔트로피 손실함수)를 사용한다는 뜻이다.\n",
        "- 따라서 로지스틱 회귀모델을 훈련(최적화)한다는 것이다."
      ],
      "metadata": {
        "id": "1q-vtAZXNZ7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습하기  # train_scaled를 써서 train셋을 한 번에 다 쓰는 \"배치 경사 하강법\"인것 같지만 여기서 하나씩 꺼내서 쓴다.\n",
        "sc.fit(train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZZRcqjiL8nb",
        "outputId": "ab65b0c1-d7ce-4fe1-88bb-6f5fd0379e4a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(loss='log', max_iter=10, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가하기\n",
        "print(sc.score(train_scaled, y_train))  # 분류 문제이기 때문에 정확도(accuracy), 회귀라면 r2\n",
        "print(sc.score(test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOst7TwyLwOJ",
        "outputId": "52583f3d-c2a7-4953-d621-a48969a0ea8d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.773109243697479\n",
            "0.775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### partial_fit(): 기존에 학습했던 w(가중치)와 b(편향)을 유지하면서 다시 또 훈련하는 것"
      ],
      "metadata": {
        "id": "p3oTz6fQOuLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# partial_fit(): 기존에 학습했던 w(가중치)와 b(편향)을 유지하면서 다시 또 훈련하는 것\n",
        "sc.partial_fit(train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnPtYS43MUVV",
        "outputId": "4a763f9e-d706-49db-ab09-69508d882562"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(loss='log', max_iter=10, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sc.score(train_scaled, y_train))\n",
        "print(sc.score(test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF27jJQ-OSsC",
        "outputId": "460e24c8-388f-4acb-ef5d-0c4b4a84ff3d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8067226890756303\n",
            "0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 에포크와 과대/과소적합"
      ],
      "metadata": {
        "id": "dS2tGMc2OY7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 조기종료(Early Stopping)\n",
        "- 과대적합이 시작하기 전에 훈련을 멈추는 것"
      ],
      "metadata": {
        "id": "xXINCwkbSpar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "qKQxwNMbP04h"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SGDClassifier(loss='log', random_state=42)"
      ],
      "metadata": {
        "id": "OMCxUSvBP2UL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = []\n",
        "test_score = []\n",
        "classes = np.unique(y_train)"
      ],
      "metadata": {
        "id": "TtoHcSevP7ns"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### partial_fit()\n",
        " - 앞에 fit()을 안 써주면 이 모델이 찾아야될 클래스 개수를 알 수 없다.\n",
        " - partial_fit()는 훈련세트의 일부분만 주어질 수 있다고 가정한다.\n",
        " - 따라서 partial_fit()만 쓸 경우에는 매개변수로 classes를 줘서 클래스들을 알려줘야 한다."
      ],
      "metadata": {
        "id": "v97NtHuITjXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(0, 300):\n",
        "  sc.partial_fit(train_scaled, y_train, classes=classes)\n",
        "  train_score.append(sc.score(train_scaled, y_train))\n",
        "  test_score.append(sc.score(test_scaled, y_test))"
      ],
      "metadata": {
        "id": "Xa5mz6MLQBkK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Iot_HOxvQRDy"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_score)\n",
        "plt.plot(test_score)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "xa13gUqPQWhZ",
        "outputId": "ebe862ec-e4df-4b69-ceb9-9cd09196dd65"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- epoch가 약 100일 때, train과 test 차이가 제일 적다.\n",
        "- 그 이상 학습하는 것은 자원낭비로 볼 수 있다.\n",
        "  - 과대적합이기도 하다."
      ],
      "metadata": {
        "id": "RoVQwF4KUqPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 따라서 이번엔 max_iter에 100만 준다.\n",
        "sc = SGDClassifier(loss='log', max_iter=100, tol=None, random_state=42)"
      ],
      "metadata": {
        "id": "U-fnuzScQfSi"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc.fit(train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQmjF63kQzKw",
        "outputId": "0913e643-04e0-4dc0-fdf2-065bf6ea57e5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(loss='log', max_iter=100, random_state=42, tol=None)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sc.score(train_scaled, y_train))\n",
        "print(sc.score(test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG58nJoIQzUD",
        "outputId": "c07b27da-ecc0-44d0-c18b-e42ab8696978"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.957983193277311\n",
            "0.925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hinge는 SVM알고리즘을 의미한다.\n",
        "sc = SGDClassifier(loss='hinge', max_iter=100, tol=None, random_state=42)"
      ],
      "metadata": {
        "id": "DS-aeSKpQ3Rk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc.fit(train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSn-69OMQ-CZ",
        "outputId": "31fd97bc-8d92-48a7-ba0c-9336982a9496"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(max_iter=100, random_state=42, tol=None)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sc.score(train_scaled, y_train))\n",
        "print(sc.score(test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4HXSTtHRAfZ",
        "outputId": "ff2296da-3958-4f87-a918-6ac2f01dafa3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9495798319327731\n",
            "0.925\n"
          ]
        }
      ]
    }
  ]
}